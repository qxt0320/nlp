# 中文邮件垃圾分类器

## 核心功能说明

本项目实现了一个基于机器学习的中文邮件垃圾分类系统，能够自动识别邮件是"垃圾邮件"还是"普通邮件"。系统支持两种不同的特征提取方法：高频词特征和TF-IDF加权特征，可以通过参数灵活切换。

### 算法基础

该项目采用多项式朴素贝叶斯分类器(Multinomial Naive Bayes)作为核心算法。朴素贝叶斯是一种基于贝叶斯定理的概率分类器，它的"朴素"之处在于假设特征之间相互独立。

#### 贝叶斯定理
贝叶斯定理用于计算条件概率，其公式为：

```
P(A|B) = P(B|A) * P(A) / P(B)
```

在邮件分类任务中，我们需要计算给定一封邮件的条件下，它属于垃圾邮件或普通邮件的概率。应用贝叶斯定理，可以表示为：

```
P(类别|邮件) = P(邮件|类别) * P(类别) / P(邮件)
```

其中：
- P(类别|邮件)：给定邮件内容，属于某个类别的概率（后验概率）
- P(邮件|类别)：给定类别，观察到该邮件内容的概率（似然）
- P(类别)：类别的先验概率
- P(邮件)：邮件内容的边缘概率

#### 朴素贝叶斯分类器的特征独立性假设

朴素贝叶斯的"朴素"假设是指特征之间条件独立，即：

```
P(x₁, x₂, ..., xₙ | y) = P(x₁|y) * P(x₂|y) * ... * P(xₙ|y)
```

在邮件分类中，这意味着我们假设每个词语的出现与其他词语无关，仅与邮件类别有关。尽管这一假设在现实中通常不成立（词语之间往往存在关联），但朴素贝叶斯仍然能在文本分类任务中取得良好效果。

#### 多项式朴素贝叶斯

多项式朴素贝叶斯特别适用于文本分类，它假设特征服从多项式分布。在邮件分类中，它计算特征词在垃圾邮件和普通邮件中出现的条件概率，然后将这些条件概率相乘（实际实现中通常采用对数相加以避免浮点数下溢），得到最终的分类结果。

### 数据处理流程

本项目的数据处理流程包括以下步骤：

1. **文本读取**：从文件系统读取邮件文本内容
2. **文本预处理**：
   - 去除标点符号、数字等无效字符
   - 使用正则表达式过滤：`re.sub(r'[.【】0-9、——。，！~\*]', '', line)`
3. **分词处理**：
   - 使用jieba分词库对中文文本进行切词：`jieba.cut(line)`
   - 这一步将中文文本切分成有意义的词语单元
4. **停用词过滤**：
   - 过滤长度为1的词语：`filter(lambda word: len(word) > 1, line)`
   - 这一步可以去除一些对分类贡献不大的单字词语

### 特征构建过程

本项目支持两种特征构建方法：高频词特征和TF-IDF加权特征。

#### 高频词特征选择

高频词特征是基于词频统计的特征选择方法：

1. 统计所有训练文档中的词语及其出现频率
2. 选取出现频率最高的N个词（本项目中N=100）作为特征词
3. 对每篇文档，计算特征词在文档中的出现次数，形成特征向量

数学表达:
- 设 `Count(word, doc)` 表示词语在文档中的出现次数
- 特征向量: `[Count(word₁, doc), Count(word₂, doc), ..., Count(wordₙ, doc)]`

高频词特征的优点是简单直观，但缺点是可能过度强调了一些常见词。

#### TF-IDF加权特征

TF-IDF(Term Frequency-Inverse Document Frequency)是一种统计方法，用于评估一个词语对于一个文档集合中的某一篇文档的重要程度：

1. TF(Term Frequency)：词频，表示词语在文档中出现的频率
   ```
   TF(t,d) = (词语t在文档d中的出现次数) / (文档d中的词语总数)
   ```

2. IDF(Inverse Document Frequency)：逆文档频率，表示词语提供的信息量
   ```
   IDF(t) = log((文档总数) / (包含词语t的文档数 + 1))
   ```
   
3. TF-IDF权重计算
   ```
   TF-IDF(t,d) = TF(t,d) * IDF(t)
   ```

TF-IDF加权特征的优势在于：
- 能够降低常见词的权重（这些词在所有文档中都频繁出现）
- 提高罕见词的权重（这些词可能更具有区分能力）
- 为每个词语分配一个反映其在特定文档中重要性的权重

在本项目中，TF-IDF特征通过sklearn的TfidfVectorizer实现，它自动完成了TF-IDF权重的计算。

## 高频词/TF-IDF两种特征模式的切换方法

本项目支持通过参数灵活切换两种特征提取方式。使用方法如下：

### 训练模型

```python
# 使用高频词特征训练模型
high_freq_model, high_freq_vectorizer = train_model(feature_type='high_freq', top_num=100)

# 使用TF-IDF加权特征训练模型
tfidf_model, tfidf_vectorizer = train_model(feature_type='tfidf', top_num=100)
```

### 进行预测

```python
# 使用高频词特征模型进行预测
result = predict('邮件_files/151.txt', high_freq_model, high_freq_vectorizer, 'high_freq')

# 使用TF-IDF加权特征模型进行预测
result = predict('邮件_files/151.txt', tfidf_model, tfidf_vectorizer, 'tfidf')
```

通过这种方式，用户可以方便地比较两种特征提取方法的性能差异，选择更适合特定场景的模型。
